{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IkTh96KDVFlO"
   },
   "outputs": [],
   "source": [
    "!pip install faker psycopg2-binary\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION & SETUP\n",
    "# ==========================================\n",
    "fake = Faker()\n",
    "Faker.seed(67)\n",
    "np.random.seed(67)\n",
    "\n",
    "# Theater Configuration (The \"Weighted Cities\" Logic)\n",
    "THEATERS = {\n",
    "    'Tunis': {\n",
    "        'id': 1,\n",
    "        'name': 'Cin√©Insights Tunis (Capital)',\n",
    "        'base_traffic': 150, # Avg tickets per day\n",
    "        'base_price': 15.0,  # TND\n",
    "        'capacity_factor': 1.0\n",
    "    },\n",
    "    'Sousse': {\n",
    "        'id': 2,\n",
    "        'name': 'Cin√©Insights Sousse (Pearl)',\n",
    "        'base_traffic': 90,  # Avg tickets per day\n",
    "        'base_price': 12.0,  # TND\n",
    "        'capacity_factor': 0.6\n",
    "    },\n",
    "    'Sfax': {\n",
    "        'id': 3,\n",
    "        'name': 'Cin√©Insights Sfax (Industrial)',\n",
    "        'base_traffic': 60,  # Avg tickets per day\n",
    "        'base_price': 10.0,  # TND\n",
    "        'capacity_factor': 0.4\n",
    "    }\n",
    "}\n",
    "\n",
    "# Date Range (Matching your weather data)\n",
    "START_DATE = datetime(2023, 12, 20)\n",
    "END_DATE = datetime(2025, 12, 20)\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATA LOADING & PREP\n",
    "# ==========================================\n",
    "print(\"Loading Source Data...\")\n",
    "\n",
    "# Load Movies\n",
    "df_movies = pd.read_csv('filtered_tmdb_movies_sample.csv')\n",
    "df_movies['release_date'] = pd.to_datetime(df_movies['release_date'])\n",
    "# Clean genres (take the first one as primary for logic simplicity)\n",
    "df_movies['primary_genre'] = df_movies['genres'].apply(lambda x: x.split(',')[0] if pd.notnull(x) else 'Drama')\n",
    "\n",
    "# Load Weather\n",
    "df_weather = pd.read_csv('tunisia_historical_weather.csv')\n",
    "df_weather['date'] = pd.to_datetime(df_weather['date'])\n",
    "\n",
    "print(f\"Loaded {len(df_movies)} movies and {len(df_weather)} weather records.\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. HELPER FUNCTIONS (The \"Business Logic\")\n",
    "# ==========================================\n",
    "\n",
    "def get_day_weight(date_obj):\n",
    "    \"\"\"\n",
    "    Weighted Days: Weekend multiplier.\n",
    "    Fri(4), Sat(5), Sun(6)\n",
    "    \"\"\"\n",
    "    day_num = date_obj.weekday()\n",
    "    if day_num == 4: return 1.3  # Friday\n",
    "    if day_num == 5: return 1.5  # Saturday\n",
    "    if day_num == 6: return 1.4  # Sunday\n",
    "    return 0.8  # Weekdays are slower\n",
    "\n",
    "def get_weather_impact(weather_row):\n",
    "    \"\"\"\n",
    "    Weather Logic:\n",
    "    Rain/Cold -> People go to cinema (+ Impact)\n",
    "    Hot/Clear -> People go to beach (- Impact)\n",
    "    \"\"\"\n",
    "    if str(weather_row['weather_state']).strip() in ['Rainy', 'Stormy', 'Cold']:\n",
    "        return 1.25 # Boost\n",
    "    elif str(weather_row['temp_category']).strip() == 'Hot' and str(weather_row['weather_state']).strip() == 'Clear':\n",
    "        return 0.75 # Penalty (Beach day)\n",
    "    return 1.0 # Neutral\n",
    "\n",
    "def get_price_elasticity(base_price, movie_rating):\n",
    "    \"\"\"\n",
    "    Price Logic:\n",
    "    Higher rating (> 7.5) = Premium Price.\n",
    "    Higher price = Slightly lower purchase probability (Elasticity).\n",
    "    \"\"\"\n",
    "    final_price = base_price\n",
    "    if movie_rating > 7.5:\n",
    "        final_price += 2.0 # Premium for good movies\n",
    "\n",
    "    # Simple elasticity: higher price -> slightly lower volume factor\n",
    "    elasticity_factor = 1.0\n",
    "    if final_price > 14:\n",
    "        elasticity_factor = 0.9\n",
    "\n",
    "    return final_price, elasticity_factor\n",
    "\n",
    "def generate_customer_profile(genre):\n",
    "    \"\"\"\n",
    "    Generates a customer based on Movie Genre assumptions.\n",
    "    \"\"\"\n",
    "    # 0 = Male, 1 = Female\n",
    "    gender_prob = 0.5\n",
    "    age_min, age_max = 16, 60\n",
    "\n",
    "    if genre in ['Action', 'Thriller', 'War', 'Crime']:\n",
    "        gender_prob = 0.3 # More Male\n",
    "        age_min, age_max = 18, 45\n",
    "    elif genre in ['Romance', 'Drama']:\n",
    "        gender_prob = 0.7 # More Female\n",
    "        age_min, age_max = 20, 50\n",
    "    elif genre in ['Animation', 'Family']:\n",
    "        gender_prob = 0.5\n",
    "        age_min, age_max = 12, 45 # Families\n",
    "    elif genre in ['Horror']:\n",
    "        gender_prob = 0.4\n",
    "        age_min, age_max = 16, 30\n",
    "\n",
    "    sex = 'F' if np.random.random() < gender_prob else 'M'\n",
    "    age = np.random.randint(age_min, age_max)\n",
    "    name = fake.name_female() if sex == 'F' else fake.name_male()\n",
    "\n",
    "    return name, sex, age\n",
    "\n",
    "# ==========================================\n",
    "# 4. DATA GENERATION LOOP\n",
    "# ==========================================\n",
    "customers_list = []\n",
    "sales_list = []\n",
    "customer_id_counter = 1001\n",
    "transaction_id_counter = 50001\n",
    "\n",
    "current_date = START_DATE\n",
    "print(\"Starting Data Generation (This may take a minute)...\")\n",
    "\n",
    "while current_date <= END_DATE:\n",
    "    date_str = current_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Get movies active (Assume movies screen for 4 weeks after release, roughly)\n",
    "    # Since dataset is historic, we just pick random subset of 8 movies per day for variety\n",
    "    daily_movies = df_movies.sample(n=8)\n",
    "\n",
    "    for city_key, city_data in THEATERS.items():\n",
    "        # 1. Get Weather for this City/Date\n",
    "        w_row = df_weather[\n",
    "            (df_weather['city'] == city_key) &\n",
    "            (df_weather['date'] == current_date)\n",
    "        ]\n",
    "\n",
    "        if w_row.empty:\n",
    "            weather_mult = 1.0\n",
    "        else:\n",
    "            weather_mult = get_weather_impact(w_row.iloc[0])\n",
    "\n",
    "        # 2. Calculate Traffic Volume\n",
    "        day_mult = get_day_weight(current_date)\n",
    "        base_vol = city_data['base_traffic']\n",
    "\n",
    "        # Total expected tickets for this city today\n",
    "        daily_potential = int(base_vol * day_mult * weather_mult)\n",
    "\n",
    "        # Distribute potential across the 8 movies\n",
    "        for _, movie in daily_movies.iterrows():\n",
    "            # Runtime Logic: Long movies (>150m) have fewer screenings -> 20% less capacity\n",
    "            runtime_penalty = 0.8 if movie['runtime'] > 150 else 1.0\n",
    "\n",
    "            # Price Calculation\n",
    "            price, elasticity = get_price_elasticity(city_data['base_price'], movie['vote_average'])\n",
    "\n",
    "            # Rating Impact (Better movies sell more)\n",
    "            rating_mult = 1.0 + ((movie['vote_average'] - 6.0) / 10.0) # slightly boosts if > 6\n",
    "\n",
    "            # Calculate final tickets for this movie\n",
    "            tickets_for_movie = int(\n",
    "                (daily_potential / 8) * # Share of daily traffic\n",
    "                runtime_penalty *\n",
    "                elasticity *\n",
    "                rating_mult *\n",
    "                np.random.uniform(0.8, 1.2) # Random noise\n",
    "            )\n",
    "\n",
    "            # Generate Transactions\n",
    "            for _ in range(tickets_for_movie):\n",
    "                # 80% chance it's an existing customer, 20% new\n",
    "                if len(customers_list) > 0 and np.random.random() > 0.2:\n",
    "                    cust_id = random.choice(customers_list)['customer_id']\n",
    "                else:\n",
    "                    # New Customer\n",
    "                    c_name, c_sex, c_age = generate_customer_profile(movie['primary_genre'])\n",
    "                    cust_id = customer_id_counter\n",
    "                    customers_list.append({\n",
    "                        'customer_id': cust_id,\n",
    "                        'name': c_name,\n",
    "                        'gender': c_sex,\n",
    "                        'age': c_age,\n",
    "                        'email': f\"user{cust_id}@example.com\",\n",
    "                        'city': city_key, # Customer lives in this city\n",
    "                        'created_at': date_str\n",
    "                    })\n",
    "                    customer_id_counter += 1\n",
    "\n",
    "                # Create Sale Record\n",
    "                sales_list.append({\n",
    "                    'transaction_id': transaction_id_counter,\n",
    "                    'date_key': date_str, # Connecting to Time Dimension\n",
    "                    'customer_id': cust_id,\n",
    "                    'movie_id': movie['id'],\n",
    "                    'theater_id': city_data['id'],\n",
    "                    'city': city_key,\n",
    "                    'ticket_price': round(price, 2),\n",
    "                    'quantity': 1, # Simplified to 1 ticket per trans for granularity\n",
    "                    'total_amount': round(price, 2)\n",
    "                })\n",
    "                transaction_id_counter += 1\n",
    "\n",
    "    current_date += timedelta(days=1)\n",
    "\n",
    "# ==========================================\n",
    "# 5. EXPORT\n",
    "# ==========================================\n",
    "df_customers = pd.DataFrame(customers_list)\n",
    "df_sales = pd.DataFrame(sales_list)\n",
    "\n",
    "print(f\"Generation Complete!\")\n",
    "print(f\"Total Customers Created: {len(df_customers)}\")\n",
    "print(f\"Total Transactions Created: {len(df_sales)}\")\n",
    "\n",
    "# Save to CSV for the next Phase (ETL)\n",
    "df_customers.to_csv('app_customers.csv', index=False)\n",
    "df_sales.to_csv('app_sales.csv', index=False)\n",
    "print(\"Files saved: 'app_customers.csv' and 'app_sales.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wDID_2vOOdjK",
    "outputId": "94ff144b-b21c-416e-a1ad-226d476c536a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.12/dist-packages (2.9.11)\n",
      "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.12/dist-packages (2.0.45)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (4.15.0)\n",
      "‚úÖ Tables `app_customers`, `app_theaters`, and `app_sales` created successfully.\n",
      "‚è≥ Uploading Customers... (This might take a moment)\n",
      "‚è≥ Uploading Theaters...\n",
      "‚è≥ Uploading Sales... (This is the big one)\n",
      "üéâ SUCCESS! All data uploaded to PostgreSQL.\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary sqlalchemy\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# ==========================================\n",
    "# 1. DATABASE CONNECTION CONFIG\n",
    "# ==========================================\n",
    "# REPLACE WITH YOUR GOOGLE CLOUD SQL DETAILS\n",
    "db_config = {\n",
    "    'user': 'cinema_admin',          # Default user is usually 'postgres'\n",
    "    'password': '<DB_PASSWORD>',    # replaced sensitive value\n",
    "    'host': '<DB_HOST>',            # replaced sensitive value\n",
    "    'port': '5432',\n",
    "    'dbname': 'cinema_db'         # Database name (create a specific one if you want)\n",
    "}\n",
    "\n",
    "# Create the connection string\n",
    "connection_str = f\"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['dbname']}\"\n",
    "engine = create_engine(connection_str)\n",
    "\n",
    "# ==========================================\n",
    "# 3. UPLOAD DATA\n",
    "# ==========================================\n",
    "\n",
    "# 3.1 Load CSVs generated in the previous step\n",
    "try:\n",
    "    df_customers = pd.read_csv('app_customers.csv')\n",
    "    df_sales = pd.read_csv('app_sales.csv')\n",
    "\n",
    "    # 3.2 Create the Theaters DataFrame manually (since it wasn't a CSV)\n",
    "    theaters_data = [\n",
    "        {'theater_id': 1, 'name': 'Cin√©Insights Tunis (Capital)', 'city': 'Tunis', 'capacity_factor': 1.0},\n",
    "        {'theater_id': 2, 'name': 'Cin√©Insights Sousse (Pearl)', 'city': 'Sousse', 'capacity_factor': 0.6},\n",
    "        {'theater_id': 3, 'name': 'Cin√©Insights Sfax (Industrial)', 'city': 'Sfax', 'capacity_factor': 0.4}\n",
    "    ]\n",
    "    df_theaters = pd.DataFrame(theaters_data)\n",
    "\n",
    "    # 3.3 Upload to SQL (if_exists='append' adds data to the tables we just made)\n",
    "    print(\"‚è≥ Uploading Customers... (This might take a moment)\")\n",
    "    df_customers.to_sql('app_customers', engine, if_exists='append', index=False, method='multi', chunksize=1000)\n",
    "\n",
    "    print(\"‚è≥ Uploading Theaters...\")\n",
    "    df_theaters.to_sql('app_theaters', engine, if_exists='append', index=False)\n",
    "\n",
    "    print(\"‚è≥ Uploading Sales... (This is the big one)\")\n",
    "    df_sales.to_sql('app_sales', engine, if_exists='append', index=False, method='multi', chunksize=1000)\n",
    "\n",
    "    print(\"üéâ SUCCESS! All data uploaded to PostgreSQL.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during data upload: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "azu58hkIZQw4",
    "outputId": "d93f147f-ebb9-4944-caa8-1a8eadf3cee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TEST: Row Counts ---\n",
      "|   total_customers |   total_sales |   total_theaters |\n",
      "|------------------:|--------------:|-----------------:|\n",
      "|             48031 |        241418 |                3 |\n",
      "\n",
      "--- TEST: City Logic Verification (Tunis should be top) ---\n",
      "| city   |   transaction_count |    total_revenue |\n",
      "|:-------|--------------------:|-----------------:|\n",
      "| Tunis  |              117062 |      1.80674e+06 |\n",
      "| Sousse |               75629 | 940448           |\n",
      "| Sfax   |               48727 | 508424           |\n",
      "\n",
      "--- TEST: Day of Week Logic (Fri-Sun should be highest) ---\n",
      "| day_name   |   transaction_count |\n",
      "|:-----------|--------------------:|\n",
      "| Monday     |               25289 |\n",
      "| Tuesday    |               25837 |\n",
      "| Wednesday  |               26347 |\n",
      "| Thursday   |               25582 |\n",
      "| Friday     |               43261 |\n",
      "| Saturday   |               49610 |\n",
      "| Sunday     |               45492 |\n",
      "\n",
      "--- TEST: Top Ticket Prices (Check for Premium Pricing) ---\n",
      "|   ticket_price |   sales_volume |\n",
      "|---------------:|---------------:|\n",
      "|             17 |          25405 |\n",
      "|             15 |          91657 |\n",
      "|             14 |          16450 |\n",
      "|             12 |          69756 |\n",
      "|             10 |          38150 |\n",
      "\n",
      "--- TEST: Integrity Check (Should be Empty) ---\n",
      "‚ö†Ô∏è Result is empty.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP CONNECTION (Same as before)\n",
    "# ==========================================\n",
    "# Re-use the config from the previous step\n",
    "db_config = {\n",
    "    'user': 'cinema_admin',          # Default user is usually 'postgres'\n",
    "    'password': '<DB_PASSWORD>',    # replaced sensitive value\n",
    "    'host': '<DB_HOST>',            # replaced sensitive value\n",
    "    'port': '5432',\n",
    "    'dbname': 'cinema_db'         # Database name (create a specific one if you want)\n",
    "}\n",
    "connection_str = f\"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['dbname']}\"\n",
    "engine = create_engine(connection_str)\n",
    "\n",
    "def run_test(title, query):\n",
    "    print(f\"\\n--- TEST: {title} ---\")\n",
    "    try:\n",
    "        df = pd.read_sql(query, engine)\n",
    "        if df.empty:\n",
    "            print(\"‚ö†Ô∏è Result is empty.\")\n",
    "        else:\n",
    "            print(df.to_markdown(index=False)) # Markdown format looks good in Colab logs\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. EXECUTE TESTS\n",
    "# ==========================================\n",
    "\n",
    "# TEST 1: Basic Row Counts\n",
    "# Goal: Ensure we have thousands of rows, not zero.\n",
    "query_counts = \"\"\"\n",
    "SELECT\n",
    "    (SELECT COUNT(*) FROM app_customers) as total_customers,\n",
    "    (SELECT COUNT(*) FROM app_sales) as total_sales,\n",
    "    (SELECT COUNT(*) FROM app_theaters) as total_theaters;\n",
    "\"\"\"\n",
    "run_test(\"Row Counts\", query_counts)\n",
    "\n",
    "\n",
    "# TEST 2: Verify \"Weighted Cities\" Logic\n",
    "# Goal: Tunis should have significantly more sales than Sfax.\n",
    "# Logic from generator: Tunis (High), Sousse (Med), Sfax (Low)\n",
    "query_city_logic = \"\"\"\n",
    "SELECT\n",
    "    city,\n",
    "    COUNT(*) as transaction_count,\n",
    "    SUM(total_amount) as total_revenue\n",
    "FROM app_sales\n",
    "GROUP BY city\n",
    "ORDER BY transaction_count DESC;\n",
    "\"\"\"\n",
    "run_test(\"City Logic Verification (Tunis should be top)\", query_city_logic)\n",
    "\n",
    "\n",
    "# TEST 3: Verify \"Weighted Days\" Logic\n",
    "# Goal: Friday/Saturday/Sunday should be higher than Monday/Tuesday.\n",
    "query_day_logic = \"\"\"\n",
    "SELECT\n",
    "    TO_CHAR(date_key, 'Day') as day_name,\n",
    "    COUNT(*) as transaction_count\n",
    "FROM app_sales\n",
    "GROUP BY TO_CHAR(date_key, 'Day'), EXTRACT(ISODOW FROM date_key)\n",
    "ORDER BY EXTRACT(ISODOW FROM date_key);\n",
    "\"\"\"\n",
    "run_test(\"Day of Week Logic (Fri-Sun should be highest)\", query_day_logic)\n",
    "\n",
    "\n",
    "# TEST 4: Price & Movie Rating Correlation\n",
    "# Goal: See if expensive tickets correlate with higher rated movies.\n",
    "# We join sales with your movies CSV (conceptually, but here we check the price distribution)\n",
    "query_price_check = \"\"\"\n",
    "SELECT\n",
    "    ticket_price,\n",
    "    COUNT(*) as sales_volume\n",
    "FROM app_sales\n",
    "GROUP BY ticket_price\n",
    "ORDER BY ticket_price DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "run_test(\"Top Ticket Prices (Check for Premium Pricing)\", query_price_check)\n",
    "\n",
    "\n",
    "# TEST 5: Data Integrity Check\n",
    "# Goal: Ensure no negative prices or null dates.\n",
    "query_integrity = \"\"\"\n",
    "SELECT * FROM app_sales\n",
    "WHERE ticket_price < 0 OR date_key IS NULL\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "run_test(\"Integrity Check (Should be Empty)\", query_integrity)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
